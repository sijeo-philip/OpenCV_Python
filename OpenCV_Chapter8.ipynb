{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0924f5",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "Evaluation Metrics are used to assess the performance of train models in machine learning:\n",
    "##### Confusion Matrix: \n",
    "A confusion Matrix summarizes the performance of a classification model. A Confusion matrix consists of:\n",
    "##### True Positive (TP):\n",
    "Instances that are correctly predicted as positive by the model\n",
    "##### True Negative (TN):\n",
    "Instances that are correctly predicted as negative by the model\n",
    "##### False Positive(FP):\n",
    "Instances that are incorrectly predicted as positive by the model when the actual class is negative (Type 1 Error)\n",
    "##### False Negative(FN):\n",
    "Instances that are incorrectly predicted as negative by the model when the actual class is positive (Type 2 Error)\n",
    "\n",
    "Based on the values of the confusion matrix, several evaluation metrics can be derived, including accuracy, precision, recall, and F1-Score, which provide a more comprehensive assessment of the model's performance accross different classes.\n",
    "##### Accuracy: \n",
    "Accuracy measures the overall correctness of predictions  made by a classification model. It is the ration of correctly predicted samples to the total number of samples. Accuracy is calculated as\n",
    "\n",
    "****Accuracy = (TP + TN)/(TP + TN + FP + FN)****\n",
    "\n",
    "##### Precision:\n",
    "Precision focuses on the accuracy of the positive predictions made by a classification model. Precision is calculated as \n",
    "\n",
    "****Precision = TP/(TP + FP)****\n",
    "\n",
    "##### Recall: \n",
    "Or Sensitivy is the true positive rate which measures the propotion of true positive predictions out of the total actual positive instances, Mathematically, recall is calculated as \n",
    "\n",
    "****Recall = TP/(TP + FN)****\n",
    "\n",
    "##### F1-Score:\n",
    "The F1-Score is the harmonic mean of precisino and recall. It provides a balanced measure of a model's performance by considering  both precision and recall. F1-Score can be calculated as:\n",
    "\n",
    "****F1-Score = 2 * (Precision * Recall)/(Precision + Recall)****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596af0e",
   "metadata": {},
   "source": [
    "## Hyperparameters and Tuning\n",
    "Hyperparameters are settings that determine how a machine learning model learns and makes predictions. These parameters are not learned from teh data but are predefined by the user and significantly influence the model's performance and behavior. Properly tuning hyperparameters is essential to optimize a model's performance for a specific task.\n",
    "Hyperparameter tuning is a crucial aspect of machine learning model development. Hyperparameters are settings that we must specify before training the model, and they significantly impact a model's performance. Tuning involves finding the best combination of hyperparameters to optimize a model's performance.\n",
    "The Process typically starts with selecting a range of hyperparameter values, and then various techniques such as grid search, random search, or Bayesian optimization are employed to systematically explore these values. Cross Validation is often used to evaluate model performance for different hyperparameter configurations, ensuring that the model generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418b65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b7ff4e",
   "metadata": {},
   "source": [
    "## Edges and Contours\n",
    "### Filters for Image Gradients\n",
    "\n",
    "####  Sobel Filters\n",
    "######  Sobel filters are very commonly used type of spatial filter that calculate the gradients in an image by performing convolution operations. They are primarily used for edge detection due to their simplicity and effectiveness in capturing the edge information. \n",
    "###### The Sobel filter consists of two types of kernels, one for computing the image gradients in the horizontal or the X direction and the other for computing the gradients in vertical or the Y direction .\n",
    "###### The SobelX kernel calculates the image gradients in the X direction and emphasizes the vertical edges in the image. The SobelX kernel enhances vertical edges by assigning negative values to one side and positive values to the other side. This creates a larger difference in values , effectively enhancing the vertical edges in the image. This arrangement accentuates the contrast between the two sides of the vertical edges. Similarly SobelY operator calculates the image gradients in the Y direction and emphasizes the horizontal edges in an image. The SobelY kernel assigns negative and positive values but in the horizontal edges in the image, thus enhancing the contrast between the two sides of the horizontal edges. Together both of the kernels make an effective gradient computation mechanism effectively calculating the gradient magnitude and orientation in the image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74549fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"Images/Input Images/Chapter 7/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#Compute the gradient along x and y directions\n",
    "gradient_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Gradient X\", gradient_x)\n",
    "cv2.imshow(\"Gradient Y\", gradient_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa18058",
   "metadata": {},
   "source": [
    "### Scharr Operator\n",
    "##### The Scharr Operators are a variation of the Sobel operators used for gradient calcualation. They are used to provide a more accurate and rotationally symmetric gradient estimate when compared to the Sobel Operators. Scharr Operators are limited to 3x3 kernel size. Similar to Sobel operators we have seperate Scharr Kernelss for the X and Y direction. The Scharr kernels provide emphasis on the central rows and columns compared to the Sobel operators, which helps in acheiving better rotational symmetry preserving more high frequency information in the gradient estimation. Sobel operators and Scharr operators are both used for finding image gradient, However Scharr operators are sometimes preferred over Sobel operators for a couple of reasons, even though they serve a similar purpose.\n",
    "##### Improved Sensitivity:\n",
    "Scharr operators are more sensitive to subtle changes in image gradients compared to Sobel operators. They can detect edges and details that sobel might miss, making them  abetter choice wehen you need precise edge detection. \n",
    "\n",
    "##### Better rotation invariance: \n",
    "Sobel operators are sensitive to the orientation of the edges, which means they might perform differently depending on whether the edge is horizontal, vertical, or diagonal. Scharr operators are designed to be more rotationally invariant meaning they perform consistently accross various edge orientation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6daaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Input Images/Chapter 7/image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#Compute Scharr X gradient using the cv2.Scharr function\n",
    "gradient_x = cv2.Scharr(image, cv2.CV_32F, 1, 0)\n",
    "\n",
    "#Compute Scharr-like Y gradient using the cv2.Sobel function\n",
    "gradient_y = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=-1)\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Gradient X\", gradient_x)\n",
    "cv2.imshow(\"Gradient Y\", gradient_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3cfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"Images/Input Images/Chapter 7/objects.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define Scharr-like kernels\n",
    "scharr_x = np.array([[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]], dtype=np.float32)\n",
    "scharr_y = np.array([[-3, -10, -3], [0, 0, 0], [3, 10, 3]], dtype=np.float32)\n",
    "\n",
    "#Compute Scharr like gradients\n",
    "gradient_x = cv2.filter2D(image, cv2.CV_32F, scharr_x)\n",
    "gradient_y = cv2.filter2D(image, cv2.CV_32F, scharr_y)\n",
    "\n",
    "gradient = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "cv2.imshow(\"Gradient X\", gradient_x)\n",
    "cv2.imshow(\"Gradient Y\", gradient_y)\n",
    "cv2.imshow(\"Gradient\", gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d676b",
   "metadata": {},
   "source": [
    "### Laplacian Operators\n",
    "Laplacian is another operator used to compute the gradients in an image to detect edges and regions of high intensity changes in an image. \n",
    "The Laplacian operator is a second-order derivative operator that measures the rate of change of intensity in the image. First order filters identify edges in an image by detecting local maximum or minimum values. In contrast, the Laplacian operator detects edges at points of inflection, which occur when the intensity value transitions from negative to positive or vice versa\n",
    "\n",
    "The Laplacian operator is represented by 3x3 kernel and central element fo the kernel is assigned a negative value (-4 or -8) and the surrounding elements have positive values (1 or 2). This configuration enhances the edges and intensity transitions in the image.\n",
    "The Laplacian operator not only detects edges in an image but also provides additional information about the nature of these edges. It classifies edges into two types: inward edges and outward edges. Inward edges are regions where the intensity values transition from higher to lower values, while outward edges are tghe regions where the intensity values transition from lower to higher values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2e5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Input Images/Chapter 7/12.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Laplacian with default Ksize\n",
    "laplacian_default = cv2.Laplacian(image, cv2.CV_64F)\n",
    "\n",
    "# Apply Laplacian with higher ksize (e.g. 11)\n",
    "laplacian_higher = cv2.Laplacian(image, cv2.CV_64F, ksize=7)\n",
    "\n",
    "# Convert the results to unsigned 8-bit for visualization\n",
    "laplacian_default = cv2.convertScaleAbs(laplacian_default)\n",
    "laplacian_higher = cv2.convertScaleAbs(laplacian_higher)\n",
    "\n",
    "#Display the original image and Laplacian results\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Laplacian (Default Ksize)\", laplacian_default)\n",
    "cv2.imshow(\"Laplacian (Higher ksize)\", laplacian_higher)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d235c",
   "metadata": {},
   "source": [
    "### Canny Edge Detector\n",
    "The canny edge detector is widely used algorithm for edge detection in image processing. The algorithm was developed in 1986 by John F Canny and has since become a pivotal advancement in the field of computer vision and image processing. The Canny edge detector aims to accuratel identify the boundaries of objects in an image while minimizing noise and false detections. \n",
    "\n",
    "The canny edge detector provides reliable and precise edge detection results by leveraging a set of carefully designed steps.\n",
    "\n",
    "##### Step1:\n",
    "Guassian Smoothing,The image is converted in grayscale and guassian blur is applied on the image to reduce noise. Smoothing the image will allow us to remove some details from the image, since we are not interested in the small details and want to extract the main boundaries in the image.\n",
    "\n",
    "#### Step2:\n",
    "Gradient Magnitude and direction: Gradients in an image represent the rate of change in pixel intensities in an image. Gradient magnitude represents the strength or the magnitude of the gradients while gradient direction talks about the direction or the orientation of the gradients in the image. We will calculate these parameters for each pixel in the image using gradient operators such as the Sobel and Scharr.\n",
    "\n",
    "#### Step 3:\n",
    "Non Max Suppression: Non-Max Suppression in Canny Edge detection is a process used in thinning the edges and thus accurately representing the true edges in an image. The algorithm keeps only the significant edges by preserving only the local maximum responses and thinning out any non-maximum responses.\n",
    "\n",
    "Non-Max Suppression works by iterating over each pixel in an image and comparing its values with the gradient magnitudes of neighbouring pixels in the direction perpendicular to the edge indicated by the gradient direction. Non max suppression works by performing the following steps\n",
    "1. Compute the gradient magnitude and direction of the image using gradient operators such as the Sobel or Scharr operators.\n",
    "2. Iterate over each pixel in the gradient magnitude image. \n",
    "3. Compare the gradient magnitude of the current pixel with its neighbouing pixels in the gradient direction.\n",
    "4. If the current pixel has greater magnitude than its neighbours, it is considered as a candidate for an edge pixel. If the current pixel has a lower magnitude than its neighbours, then the pixel is ignored. \n",
    "5. The value for this pixel is then set to its gradient magnitude value indicating that it is a local minimum response. Pixels that are not considered as local maxima are set to 0.\n",
    "\n",
    "By performing the non maximum supression, the algorithm ensures that only pixels with maximum gradient magnitudes along the edges are retained, while suppressing the weaker responses that do not corresponds to the sharpest edges.\n",
    "\n",
    "#### Step 4:\n",
    "Hysteresis Thresholding: There are still a few regions in the image that are not edges and need to be removed. To do that, we first choose two threshold values, a higher and a lower threshold value and use these to classify pixels into strong, weak or non edges. These threshold values have to be chosen carefully as a large range between these values will keep a lot of false edges while a narrow range might eliminate some real edges from the output.\n",
    "Pixels with thresholds higher than the upper threshold value are classified as strong edges and these pixels are kept. Pixels with lower values than the lower threshold are considered to be non-edges and these pixels are discarded as edges. \n",
    "Any values lying between the upper and lower threshold values are classified as weak edges. If the weak edge pixels are connected to a strong edge, these pixels are kept and marked as edge. Otherwise these values are discarded. This is known as edge tracking by hystersis and helps to extend and connect edges that may have been broken during thresholding. \n",
    "Output: The result is and edge map where edges are represented as white and all non-edge areas are depicted as black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81fba019",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Images/Input Images/Chapter 7/12.jpg\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcbb11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "#Compute the Gradients using Sobel Operator\n",
    "gradient_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "#Compute the magnitude and direction of the gradients\n",
    "gradient_magnitude = np.sqrt(gradient_x**2, gradient_y**2)\n",
    "gradient_direction = np.arctan2(gradient_y, gradient_x)\n",
    "cv2.imwrite('gradient_magnitude.jpg', gradient_magnitude)\n",
    "cv2.imwrite('gradient_direction.jpg', gradient_direction)\n",
    "\n",
    "#Perform non-maximum suppression\n",
    "suppressed = np.copy(gradient_magnitude)\n",
    "for i in range(1, suppressed.shape[0] -1):\n",
    "    for j in range(1, suppressed.shape[1] - 1):\n",
    "        direction = gradient_direction[i, j] * 180./np.pi\n",
    "        if ( 0 <= direction < 22.5) or (157.5 <= direction <= 180):\n",
    "            if suppressed[i, j] <= suppressed[i, j+1] or suppressed[i, j] <= suppressed[i, j - 1]:\n",
    "                suppressed[i, j] = 0\n",
    "        elif (22.5 <= direction < 67.5):\n",
    "            if suppressed[i, j] <= suppressed[i - 1, j + 1] or suppressed[i, j] <= suppressed[i + 1, j - 1]:\n",
    "                suppressed[i, j] = 0\n",
    "        elif (67.5 <= direction < 112.5):\n",
    "            if suppressed[i, j] <= suppressed[i - 1, j] or suppressed[i, j] <= suppressed[i + 1, j]:\n",
    "                suppressed[i, j] = 0\n",
    "        else:\n",
    "            if suppressed[i, j] <= suppressed[i - 1, j - 1] or suppressed[i, j] <= suppressed[i + 1, j + 1]:\n",
    "                suppressed[i, j] = 0\n",
    "                    \n",
    "cv2.imwrite('suppressed.jpg', suppressed)\n",
    "\n",
    "# Perform thresholding to classify pixels as strong or weak edges \n",
    "low_threshold = 30\n",
    "high_threshold = 100\n",
    "edges = np.zeros_like(suppressed)\n",
    "edges[suppressed >= high_threshold] = 255\n",
    "edges[suppressed <= low_threshold] = 0\n",
    "weak_edges = np.logical_and(suppressed > low_threshold, suppressed < high_threshold )\n",
    "\n",
    "# Perform edge tracking by connecting weak edges to strong edges\n",
    "strong_edges_i , strong_edges_j = np.where(edges == 255)\n",
    "for i, j in zip(strong_edges_i, strong_edges_j):\n",
    "    if np.any(weak_edges[i - 1:i + 2, j - 1:j + 2]):\n",
    "        edges[i - 1:i + 2, j - 1: j + 2] = 255\n",
    "cv2.imwrite('edges.jpg', edges)\n",
    "\n",
    "cv2.imshow('Canny Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0501039",
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edges =cv2.Canny(image, threshold1=30, threshold2=100)\n",
    "cv2.imshow('Edges', canny_edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011f3fb",
   "metadata": {},
   "source": [
    "## Introduction to Contours.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038384d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1c7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/input.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c732acc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 347, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4a5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Translation Matrix\n",
    "tx = 50  #x-direction\n",
    "ty = 100 # Y-direction\n",
    "M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "#Apply translation to the image\n",
    "rows, cols, _ = img.shape\n",
    "translated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Translated Image\", translated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c2ff7",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be08a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/input.jpg')\n",
    "\n",
    "#Rotate clockwise by 90 degrees\n",
    "rot_img_90cw = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "#Rotate counterclockwise by 90 degrees\n",
    "rot_img_90ccw = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "#Rotate by 180 degrees\n",
    "rot_img_180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Rotated 90 CW', rot_img_90cw)\n",
    "cv2.imshow('Rotated 90 CCW', rot_img_90ccw)\n",
    "cv2.imshow('Rotated 180', rot_img_180)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a23cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[511, 347]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/111.png')\n",
    "row, cols = img.shape[:2]\n",
    "print([rows,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98cfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rotation matrix\n",
    "M1 = cv2.getRotationMatrix2D((100,100), 30, 1)\n",
    "M2 = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 2)\n",
    "M3 = cv2.getRotationMatrix2D((cols/2, rows/2), -90, 1)\n",
    "\n",
    "#Perform Rotation\n",
    "rotated1 = cv2.warpAffine(img, M1, (cols, rows))\n",
    "rotated2 = cv2.warpAffine(img, M2, (cols, rows))\n",
    "rotated3 = cv2.warpAffine(img, M3, (cols, rows))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Rotated Image 1', rotated1)\n",
    "cv2.imshow('Rotated Image 2', rotated2)\n",
    "cv2.imshow('Rotated Image 3', rotated3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94425e",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7310369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/input.jpg')\n",
    "img.shape\n",
    "#Resize the image to half the size\n",
    "resized_img = cv2.resize(img, dsize=(0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "#Resize the image to specific width and height\n",
    "resized_img_1 = cv2.resize(img, (640, 480))\n",
    "\n",
    "cv2.imshow('Original Image ', img)\n",
    "cv2.imshow('Resized Image ', resized_img)\n",
    "cv2.imshow(\"Half resized image\", resized_img_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61077e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 347, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/cat.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3eb28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define new size\n",
    "new_size = (400, 400)\n",
    "\n",
    "#Compute the scaling factor for x and y axis\n",
    "sx = new_size[0]/img.shape[1]\n",
    "sy = new_size[1]/img.shape[0]\n",
    "\n",
    "#define the transformation matrix\n",
    "M = np.float32([[sx, 0, 0], [0, sy, 0]])\n",
    "\n",
    "#Apply the affine transformation\n",
    "resized_img = cv2.warpAffine(img, M, new_size)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Resized Image', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a7473",
   "metadata": {},
   "source": [
    "## Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e13ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/111.png')\n",
    "#Flip the image horizontally\n",
    "x_flip = cv2.flip(img, 1)\n",
    "#Flip the image vertically\n",
    "y_flip = cv2.flip(img, 0)\n",
    "#Flip the image on both axes\n",
    "xy_flip = cv2.flip(img, -1)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Horizontal Flip', x_flip)\n",
    "cv2.imshow('Vertical Flip', y_flip)\n",
    "cv2.imshow('Both axes', xy_flip)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700cd16",
   "metadata": {},
   "source": [
    "## Shearing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5cf12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/input.jpg')\n",
    "#Shearing Parameters\n",
    "shear_factor_x = 0.2\n",
    "shear_factor_y = 0.3\n",
    "\n",
    "#obtain shearing matrix\n",
    "M_x = np.array([[1, shear_factor_x, 0],\n",
    "              [0, 1, 0]])\n",
    "M_y = np.array([[1, 0, 0],\n",
    "               [shear_factor_y, 1, 0]])\n",
    "\n",
    "#Apply shearing transformations\n",
    "row, cols = img.shape[:2]\n",
    "sheared_image_x = cv2.warpAffine(img, M_x, (cols + int(row * shear_factor_x), row))\n",
    "sheared_image_xy = cv2.warpAffine(sheared_image_x, M_y, (cols + int(row *  shear_factor_x), row + int(cols * shear_factor_y)))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow(\"Sheared Image( X axis )\", sheared_image_x )\n",
    "cv2.imshow(\"Sheared Image( X and Y axis )\", sheared_image_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1c5ab",
   "metadata": {},
   "source": [
    "## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe97c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/input.jpg')\n",
    "\n",
    "#Define ROI coordinates\n",
    "x1, y1 = 100, 100\n",
    "x2, y2 = 300, 400\n",
    "\n",
    "#Crop Image\n",
    "cropped_img =  img[y1:y2, x1:x2]\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Cropped Image\", cropped_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983060f7",
   "metadata": {},
   "source": [
    "# Airthematic Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388cc91c",
   "metadata": {},
   "source": [
    "## Addition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765b10be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2.add() result:\n",
      " [[110 220 180]\n",
      " [ 90 255 160]\n",
      " [220 255 140]]\n",
      "Numpy Addition result:\n",
      " [[110 220 180]\n",
      " [ 90  44 160]\n",
      " [220  24 140]]\n"
     ]
    }
   ],
   "source": [
    "#Initialize two sample 3x3 Images\n",
    "img1 = np.array([[10, 20, 30],[40, 50, 60],[70, 80, 90]], dtype=np.uint8)\n",
    "img2 = np.array([[100, 200, 150],[50, 250, 100],[150, 200, 50]], dtype=np.uint8)\n",
    "\n",
    "# Add the images\n",
    "cv2_add = cv2.add(img1, img2)\n",
    "print(\"cv2.add() result:\\n\", cv2_add)\n",
    "\n",
    "#Add the images using numpy addition\n",
    "numpy_add = img1 + img2\n",
    "print(\"Numpy Addition result:\\n\", numpy_add)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d37d4e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2112, 3538, 3)\n",
      "(6000, 4000, 3)\n",
      "(2112, 3538, 3)\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('Images/Input Images/Chapter 3/image1.jpg')\n",
    "img2 = cv2.imread('Images/Input Images/Chapter 3/image2.jpg')\n",
    "print(img1.shape)\n",
    "print(img2.shape)\n",
    "\n",
    "target_row, target_cols = img1.shape[:2]\n",
    "target_size = (target_cols, target_row)\n",
    "img2 = cv2.resize(img2, target_size)\n",
    "print(img2.shape)\n",
    "# Add two images with different weights\n",
    "result = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "\n",
    "cv2.imshow('Image 1', img1)\n",
    "cv2.imshow('Image 2', img2)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc788b3",
   "metadata": {},
   "source": [
    "## Bitwise Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fec941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.zeros((400, 400), dtype=np.uint8)\n",
    "img2 = np.zeros((400, 400), dtype=np.uint8)\n",
    "\n",
    "#Draw a rectangle on img1\n",
    "cv2.rectangle(img1, (50, 50), (350, 350), (255, 255, 255), -1)\n",
    "cv2.circle(img2, (200, 200), 150, (255, 255, 255), -1)\n",
    "bitwise_and = cv2.bitwise_and(img1, img2)\n",
    "bitwise_or = cv2.bitwise_or(img1, img2)\n",
    "bitwise_xor = cv2.bitwise_xor(img1, img2)\n",
    "bitwise_not = cv2.bitwise_not(img1)\n",
    "\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.imshow('AND', bitwise_and)\n",
    "cv2.imshow('OR', bitwise_or)\n",
    "cv2.imshow('XOR', bitwise_xor)\n",
    "cv2.imshow('NOT', bitwise_not)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109254a5",
   "metadata": {},
   "source": [
    "## RGB Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06057f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 3/ss.jpg')\n",
    "im1 = img.copy()\n",
    "im2 = img.copy()\n",
    "im3 = img.copy()\n",
    "\n",
    "im1[:,:,0] = 0\n",
    "im1[:,:,1] = 0\n",
    "\n",
    "\n",
    "im2[:,:,2] = 0\n",
    "im2[:,:,1] = 0\n",
    "\n",
    "im3[:,:,2] = 0\n",
    "im3[:,:,0] = 0\n",
    "\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow(\"Red Channel\", im1)\n",
    "cv2.imshow('Blue Channel', im2)\n",
    "cv2.imshow('Green Channel',im3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9ff75",
   "metadata": {},
   "source": [
    "## Hue Saturation Value (HSV) Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa52fc",
   "metadata": {},
   "source": [
    "### Hue:\n",
    "Hue Refers to the pure color that we preceive. Hue is essentially a pure color without any white or black added to it. So, for example, all types of Blue, whether dark blue or light blue, will have the same blue hue. The Hue value ranges from 0 to 360 degrees, representing a full circle of colors. Red is located at 0 degrees, green at 120 degrees, and blue at 240 degrees,. The Hue Component in OpenCV HSV color space is a uint8 value from 0 to 255, but the actual hue range is 0 to 360 degrees. To fit this range in an 8 bit integer; values are scaled down to 0-179, where each value represents a specific hue.\n",
    "\n",
    "### Saturation:\n",
    "Saturation represents the intensity of the color. The saturation value is represented as a percentage from 0 to 100. A 100% saturation value will represent that the color is fully saturated, meaning that it has the maximum possible intensity. A 0% saturation will have no color and will be pure while pixel.\n",
    "\n",
    "### Value:\n",
    "Value is the amount of white or black added to the hue. It represents the lightness or the darkness of the color. This is also represented as a percentage, ranging from 0% to 100%. A value of 0% represents the darkest possible color(black), while a value of 100% represents the lightest possible color(white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffabab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread('Images/Input Images/Chapter 3/img.jpg')\n",
    "#BGR to grayscale\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Original Image', img_bgr)\n",
    "cv2.imshow('Grayscale Image', img_gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c44991",
   "metadata": {},
   "source": [
    "## Hue Saturation Lightness( HSL) Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba28ccb7",
   "metadata": {},
   "source": [
    "### Hue:\n",
    "Hue refers to the pure color that we perceive. This is similar to the description in the HSV channel\n",
    "\n",
    "### Saturation:\n",
    "Saturation represents the intensity of the color. This is also similar to the description of the HSV channel\n",
    "\n",
    "### Lightness:\n",
    "Lightness is the measure of how bright or dark the color is, with 0% Lightness being black and 100% lightness being white. This the useful for brightening or darkening images as well as for adding creative touches to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df9994",
   "metadata": {},
   "source": [
    "## LAB Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2228c2",
   "metadata": {},
   "source": [
    "### The LAB color space was designed to resemble the human vision system closely. This color space mimics how the human eye preceives color and thus mimics the human eye more closer than any other color space. \n",
    "\n",
    "### Lightness:\n",
    "The Lightness channel represents the lightness dimension. It describes the brightness of the image. The values are in the range of 0 to 100 where 0 is the lowest brightness(black) and 100 is the brightest (white)\n",
    "\n",
    "### A Channel( Green - Red):\n",
    "This defines the pure green color on one side and pure red color on the opposite side. The values for this dimension range from -128 to +127 and define the color between green to red channels. Negative values represent shades of green, asn as we move on the positive values, shades of red get defined by these values.\n",
    "\n",
    "### B Channel(Blue- Yellow):\n",
    "This defines pure blue color on one side and pure red color on the opposite side. The values for this dimension range from -128 to +127 and define the color between blue to yellow channels. Negative values represent shades of blue, and as er move on to the positive values, shades of yellow get defined by these values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6a564",
   "metadata": {},
   "source": [
    "## YCbCr Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac93eabb",
   "metadata": {},
   "source": [
    "#### The YCbCr color space is a color encoding system that represents colors as a combination of brightness(luma) and two color-difference (chroma). This color space seperates luminance (brightness) and chrominance (color) information, allowing for more efficient compression of images. \n",
    "\n",
    "#### YCbCr color space is similar to the RGB color space, but it uses luminance (Y), blue-difference(Cb) and red-difference(Cr) components instead of red, green and blue. Y represents the image's brightness, while Cb and Cr represent the difference between the color and the brightness. \n",
    "\n",
    "### Y Channel:\n",
    "This channel represents the brightness of the color and is sometimes referred to as the luminance channel\n",
    "\n",
    "### Cb and Cr Channel:\n",
    "These channels represent the color information of the image. The Cb channel represents the blue-difference, and the Cr channel represents the red-difference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb2d3e",
   "metadata": {},
   "source": [
    "## Grayscale\n",
    "Images in Grayscale are represnted in a single channel only and contain values from 0 to 255. This value indicated the amount of light on the pixel. A value of 0 means there is no light on the pixel, and hence the pixel's color is black. Meanwhile, a value of 255 represents the maximum and has a value of white. All the values in between are different shades of gray.\n",
    "\n",
    "### Grayscale = 0.2989 * Red + 0.5870 * Green + 0.1140 * Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8d650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

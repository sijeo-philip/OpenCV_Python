{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d8524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a866dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/test.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b55a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply erosion once to remove noise\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "img1 = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "#Apply erosion multiple times to show bad result\n",
    "img2 = cv2.erode(img, kernel, iterations=10)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Erosion\", img1)\n",
    "cv2.imshow(\"Over Erosion\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3e465",
   "metadata": {},
   "source": [
    "## Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7936f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/Input Images/Chapter 4/test2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "229f9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply erosion onces ot remove noise\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "img1 = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "#Apply erosion multiple times to show bad result\n",
    "img2 = cv2.dilate(img, kernel, iterations=5)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Dilation', img1)\n",
    "cv2.imshow('Over Dilation', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855b723",
   "metadata": {},
   "source": [
    "## Opening\n",
    "##### Erosion followed by Dilation is referred to as an opening operation in image processing. This is called opening operation as it \"opens\" up the main object in the image by removing unwanted objects or noise from the image and then restoring the object to its original size. Performing Erosion first on the image will result in the removal of small objectsor noise in the image. Following this, the dilation operation will close any gaps that have been unintentionally caused due to the erosion operation before. Opening operation can help us to remove unwanted noise, seperate objects in an image, or as precursor for other image processing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc3c36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 300x300 image with a black background\n",
    "img = np.zeros((200, 450), np.uint8)\n",
    "\n",
    "#Draw the text Opening on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, \"OPENING\", (15, 125), font, 3, (255, 255, 255), 5)\n",
    "\n",
    "# Add noise to the Image\n",
    "noise = np.zeros((200, 450), np.uint8)\n",
    "cv2.randn(noise, 0, 50)\n",
    "noisy = cv2.add(img, noise)\n",
    "\n",
    "#Define a 5x5 kernel for the erosion and dilation operations\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "#Perform erosion\n",
    "erosion = cv2.erode(img, kernel, iterations=1)\n",
    "\n",
    "#Perform Dilation on eroded image\n",
    "opening = cv2.dilate(erosion, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Noisy Image\", noisy)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.imshow(\"Opening Result\", opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fd5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 300x300 image with a black background\n",
    "img = np.zeros((200, 450), np.uint8)\n",
    "\n",
    "#Draw the text OPENING on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, \"OPENING\", (15, 25), font, 3, (255, 255, 255), 5)\n",
    "\n",
    "# Add noise to the image\n",
    "noise = np.zeros((200, 450), np.uint8)\n",
    "cv2.randn(noise, 0, 50)\n",
    "img2 = cv2.add(img, noise)\n",
    "\n",
    "#Define a 5x5 kernel for the opening operations\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "#Perform the opening operation on the image\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Noisy Image\", noisy)\n",
    "cv2.imshow(\"Opening Result\", opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8380751",
   "metadata": {},
   "source": [
    "## Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244f9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((200, 450), np.uint8)\n",
    "\n",
    "#Draw the text \"CLOSING\" on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, \"CLOSING\", (15, 125), font, 3, (255, 255, 255), 5)\n",
    "\n",
    "noisy_img = img.copy()\n",
    "\n",
    "#Create noise using difference of two images\n",
    "noise = np.zeros_like(img)\n",
    "for I in range(1000):\n",
    "    x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "    cv2.circle(noisy_img, (x, y), 1, (0, 0, 0), -1, lineType=cv2.LINE_AA)\n",
    "    \n",
    "#define kernel for closing operation \n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "\n",
    "#Perform closing operations\n",
    "dilated_img = cv2.dilate(noisy_img, kernel)\n",
    "closed_img = cv2.erode(dilated_img, kernel)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Noisy Image\", noisy_img)\n",
    "cv2.imshow(\"Dilated Image\", dilated_img)\n",
    "cv2.imshow(\"Close\", closed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d54e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((200, 450), np.uint8)\n",
    "\n",
    "# Draw the text \"OPENING\" on the image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img, \"CLOSING\", (15, 25), font, 3, (255, 255, 255), 5)\n",
    "\n",
    "noisy_img = img.copy()\n",
    "\n",
    "#Create noise using difference of the two images\n",
    "noise = np.zeros_like(img)\n",
    "for i in range(1000):\n",
    "    x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "    cv2.circle(noisy_img, (x, y), 1, (0, 0, 0), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "# dEfine kernel for closing operations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "#Apply closing operations\n",
    "closed_img = cv2.morphologyEx(noisy_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow(\"Noisy Image\", noisy_img)\n",
    "cv2.imshow(\"Closed Image\", closed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17debd04",
   "metadata": {},
   "source": [
    "## Morphological Gradient\n",
    "##### The morphological gradient is the difference between dilation and corosion operations on an image. Both operations are applied to the source image and the gradient is calculated by subtracting the eroded image from the dilated image. \n",
    "#### Morphological Gradient (G) = Dilation (D) - Erosion (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9df1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the Image\n",
    "img = cv2.imread('Images/Input Images/Chapter 4/img.jpg', 0)\n",
    "\n",
    "#Define the Kernel\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Apply morphological gradient\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "#Display the result\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow('Morphological Gradient', gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be744d",
   "metadata": {},
   "source": [
    "## Top Hat\n",
    "##### The Top Hat operation, also known as white hat operation, is used to highlight the bright regions in an image. The Top Hat operation is the difference between  the opening of an image and the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca4264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/galaxy.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#define the rectangular structuring element for the top hat operation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "#Perform the top hat operation\n",
    "top_hat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Top Hat Result\", top_hat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a1122",
   "metadata": {},
   "source": [
    "## Bottom Hat\n",
    "##### The Bottom hat operation, also known as the black hat operation, is the opposite of top hat operation and is used to highlight the dark regions of the image. The Bottom Hat operation is the difference between the closing of an image and original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74024bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#define the rectangular structuring element for the bottom hat operation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "#Perform BLACK HAT Operation\n",
    "bottom_hat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Black hat\", bottom_hat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88864587",
   "metadata": {},
   "source": [
    "## Smoothing and blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53308bce",
   "metadata": {},
   "source": [
    "### Average Blurring\n",
    "##### Average blurring is a simple and fast blurring technique used frequently in image processing. Average blurring helps us to remove noise from the image by reducing the high frequency contents of an image, resulting in a smoother image. Average blurring is a type of blurring where the value of each pixel is replaced by the average value of pixels surrounding it. The average filter is also called a box filter, is a linear filter used to implement average blurring. For best results, the size of the filter is taken in odd dimensions such as 3, 5, 7 and while we ar e allowed to use rectangular shape kernels the shape is generally kept a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe089b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/1.jpg')\n",
    "#Apply average blurring with the kernel size 3\n",
    "blurred_3 = cv2.blur(img, (3, 3))\n",
    "\n",
    "#Apply average blurring with kernel size 7\n",
    "blurred_7 = cv2.blur(img, (7, 7))\n",
    "\n",
    "#Apply avarage blurring with kernel size 15\n",
    "blurred_15 = cv2.blur(img, (15, 15))\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('blurred (3, 3)', blurred_3)\n",
    "cv2.imshow('blurred (7, 7)', blurred_7)\n",
    "cv2.imshow('blurred (15, 15)', blurred_15)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025759c",
   "metadata": {},
   "source": [
    "### Median Blur\n",
    "##### Median blurring is another popular blurring algorithm we use in image processing. Unlike average blurring, where we take the avarage value of the surrounding pixels, the median blurring the median value of the pixels inside the kernel region is used for the center pixel. Similar to average blurring, we use a kernel for median blurring with an odd dimensional filter size. The filter in median blurrign has to be square and we cannot use a rectangular size filter like we did in average blurring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201d5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/image.jpg')\n",
    "\n",
    "#Apply median blur with kernel size 3x3\n",
    "median_3 = cv2.medianBlur(img, 3)\n",
    "\n",
    "#Apply median blur wiht kernel size 7x7\n",
    "median_7 = cv2.medianBlur(img, 7)\n",
    "\n",
    "#Apply median blur with kernel size 15x15\n",
    "median_15 = cv2.medianBlur(img, 15)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Median Blur 3', median_3)\n",
    "cv2.imshow('Median Blur 7', median_7)\n",
    "cv2.imshow('Median Blur 15', median_15)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860ae151",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_img = cv2.imread('Images/Input Images/Chapter 4/22.jpg')\n",
    "#Apply median blur\n",
    "denoised_img = cv2.medianBlur(noisy_img, 3)\n",
    "\n",
    "cv2.imshow('Noisy Image', noisy_img)\n",
    "cv2.imshow('Denoised Image', denoised_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0866388",
   "metadata": {},
   "source": [
    "### Guassian Blur\n",
    "##### The next blurring operation we will discuss is the Guassian blurring. Similar to the blurring methods we saw earlier, gaussian blurring will also use a kernel in its operation. Gaussian blurring uses a special type of kernel called  the gaussian kernel for the process.  The guassian kernel is a matrix of weight applied to each pixel in an image. The kernel is defined in such a way that the center of the kernel has the highest value or weight, and as we move away from the center the weights start to decrease. This effectively means that when we apply this kernel to a pixel, the blurring operation takes place in such a way that the pixels nearer to the center pixel have more contribution to the overall value compared to pixels that are further away from it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00f206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/Input Images/Chapter 4/img.jpg')\n",
    "# Apply Guaussina blur with kernel size (5,5) and standard deviation of 0\n",
    "guassian_blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "\n",
    "# display the original and blurred images side by side\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Guassian Blurred Image', guassian_blur)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cbd5c",
   "metadata": {},
   "source": [
    "### Bilateral Filter\n",
    "##### A bilateral filter is a non linear filter that allows us to blur images while preserving the edges of the objects in the image. This makes it a popular choice for a wide range of image processing applications such as denoising and edge detection. The filters we discussed earlier only consider the spatial distance between the pixels in consideration. However, a Bilateral filter is a special type of filter as it  considers both spatial distance and the difference between the intensity values of neighbouring pixels. Edges are basically large differences in intensity values, a bilateral filter is able to take that into consideration and hence handles these differences accordingly. This feature allows the filter to preserve the edges in an image while reducing the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe6fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/Input Images/Chapter 4/image.jpg')\n",
    "\n",
    "#Apply bilateral filter wiht high sigma value\n",
    "filtered_img_high = cv2.bilateralFilter(img, 15, 200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9040fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply bilateral filter to low sigma values\n",
    "filtered_img_low = cv2.bilateralFilter(img, 15, 50, 50)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Filtered (high)', filtered_img_high)\n",
    "cv2.imshow('Filtered (low)', filtered_img_low)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb793f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
